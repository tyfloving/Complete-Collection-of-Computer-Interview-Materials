**<center>【机器学习sklearn使用技巧总结-修炼师】</center>**
&nbsp;

----------
[TOC]


# Sklearn介绍

## 🎯 1. sklearn 是什么？
## 💡 2. sklearn安装
### 🔍 3. sklearn使用
#### 3.1 工具介绍
#### 3.2 vscode安装
#### 3.3 Anaconda安装
#### 3.4 sklearn配置成功

## Sklearn数据处理
### 🎯 1. sklearn自带数据
#### 1.1 鸢尾花（Iris）数据
#### 1.2 葡萄酒（Wine）数据集
#### 1.3 波士顿房价（Boston）
### 💡 2. Sklearn中的数据处理
#### 2.1 缺失值处理
#### 2.2 特征缩放
#### 2.3 特征编码
#### 2.4 主成分分析（PCA）
### 🔍 3. 注意事项
### 🔧 4. 总结

## Sklearn分类指标
### 🎯 1. 基本介绍
### 💡 2. 使用方法
#### 2.1 混淆矩阵（Confusion Matrix）
#### 2.2 准确率（Accuracy）
#### 2.3 精确率和召回率（Precision and Recall）
#### 2.4 F1分数（F1 Score）
### 🔍 3. 进阶用法
### 🔍 4. 注意事项
### 🔧 5. 总结

## Sklearn聚类指标
### 🎯 1. 基本介绍
### 💡 2. 公式推导
#### 2.1 轮廓系数（Silhouette Coefficient）
#### 2.2 戴维森堡丁指数（Davies-Bouldin Index）
### 🔍 3. 代码实践
#### 3.1 数据生成
#### 3.2 训练聚类模型
#### 3.3 计算轮廓系数
#### 3.4 计算戴维森堡丁指数
### 🔍 4. 注意事项
### 🔍 5. 总结

## Sklearn回归指标
### 🎯 1. 基本介绍
### 💡 2. 指标介绍
#### 2.1 MAE:平均绝对误差
#### 2.2 MSE：均方误差
#### 2.3 RMSE：均方误差
#### 2.4 MAPE：平均绝对百分比误差
#### 2.5 SMAPE:平均绝对百分比误差
#### 2.6 WMAPE:加权的百分比误差
#### 2.7 决定系数（R-squared, R²）
### 🔍 3. 代码实践
#### 3.1 导入库和准备数据
#### 3.2 训练回归模型
#### 3.3 指标计算
### 🔍 4. 注意事项
### 🔍 5. 总结

## Sklearn模型线性回归：预测分析的基石
### 🎯 1. 基本介绍
### 💡 2. 理论推导
#### 2.1 数学基础知识
#### 2.2 极大似然估计(MLE)
#### 2.3 极大后验估计(MAP）
#### 2.4 岭回归
#### 2.5 Lasso回归
### 🔍 3. 代码实践
#### 3.1 自己实现
#### 3.2 sklearn线性回归使用
### 🔍 4. 注意事项

## Sklearn-逻辑回归
### 🎯 1. 基本介绍
### 💡 2. 理论介绍
### 🔍 3. 代码实践
#### 3.1 自己实现
#### 3.2 Sklearn实现
#### 3.3 LR重要参数介绍
### 🔍 4. 注意事项
### 🔍 5. 总结

## Sklearn-决策树
### 🎯 1. 基本介绍
### 💡 2. 原理介绍
#### 2.1 信息增益
#### 2.2 基尼指数
#### 2.3 CART树的原理推导
### 🔍 3. 代码实践
#### 3.1 sklearn代码实践
#### 3.2 高阶用法
### 🔍 4. 注意事项
### 🔍 5. 总结

## Sklearn-决策树可视化
### 🎯 1. 环境配置
### 💡 2. 使用方法
#### 2.1 使用决策树进行可视化
#### 2.2 xgb可视化
### 🔍 3. 注意事项

## Sklearn-svm模型
### 🎯 1. 基本介绍
### 💡 2. 原理介绍
#### 2.1 基础知识
#### 2.2 原理推导
### 🔍 3. 代码实践
#### 3.1 svm分类
#### 3.2 svm回归
### 🔍 4. 注意事项
### 🔍 5. 总结

## Sklearn-Kmeans模型
### 🎯 1. 基本介绍
### 💡 2. 公式推导
### 🔍 3. 代码实践
#### 3.1 数据准备
#### 3.2 模型训练过程
#### 3.3 可视化聚类结果
### 🔍 4. 注意事项
### 🔍 5. 总结

## Sklearn-GMM算法
### 🎯 1. 基本介绍
### 💡 2. 原理介绍
#### 2.1 EM算法
#### 2.2 GMM算法
### 🚀 3. 代码实践
### 🚀 4. 注意事项
### 🚀 5. 总结

## Sklearn-HMM-CRF
### 🎯 1. 基本介绍
### 💡 2. 原理介绍
#### 2.1 标注模型发展状况
#### 2.2 HMM算法知识点总结
##### 两个假设问题
##### 预测问题
##### viterbi算法理解
##### 模型建模理解
#### 2.3 memm算法介绍
#### 2.4 CRF算法原理
### 🔍 3. 代码实践
#### 3.1 HHM实践
#### 3.2 CRF实践
### 🔍 4. 注意事项
### 🔍 5. 总结

## Sklearn-xgboost模型
### 🎯 1. 基本介绍
### 💡 2. xgboost算法原理
### 💡 3. 使用方法
### 🔍 4. 主要参数调整
### 🔍 5. 注意事项
### 🔍 6. 总结

## Sklearn-K折交叉验证
### 🎯 1. 基本介绍
### 💡 2. 原理介绍
### 🚀 3. 使用方法
### 🔍 4. 注意事项
### 🔍 5. 总结

## Sklearn-参数搜索
### 🎯 1. 基本介绍
#### 1.1 概念介绍
#### 1.2 对比分析
### 💡 2. 代码实践
### 💡 3. 注意事项

## Sklearn-特征提取
### 🎯 1. 基本介绍
### 💡 2. 公式推导
### 💡 3. 代码实践
### 💡 4. 注意事项
### 💡 5. 总结

## Sklearn-贝叶斯参数优化器
### 🎯 1. 基本介绍
### 💡 2. 公式推导
### 💡 3. 代码实践
#### 3.1 定义目标函数
#### 3.2 贝叶斯参数优化
### 💡 4. 注意事项
### 💡 5. 总结

## Sklearn-贝叶斯平滑
### 🎯 1. 基本介绍
### 💡 2. 公式推导
### 💡 3. 代码实践
#### 3.1 创建示例数据
#### 3.2 贝叶斯平滑
### 💡 4. 注意事项
### 💡 5. 总结

### 面试总结
- 现在机器学习的岗位现在越来越少了，面试基本都是围绕：数据多大，数据怎么处理，特征怎么提取，模型的原理，对比，各个指标的优化迭代的方法进行